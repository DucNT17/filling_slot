from openai import OpenAI
import json 
import time
import asyncio
from typing import Dict, Any

clientOpenAI = OpenAI()

DEFAULT_OBJECT = {
    "kha_nang_dap_ung": "",
    "tai_lieu_tham_chieu": {
        "file": "",
        "section": "",
        "table_or_figure": "",
        "page": 0,
        "evidence": ""
    }
}

def fill_defaults(data: dict, defaults: dict) -> dict:
    """
    ƒê·ªá quy b·ªï sung c√°c tr∆∞·ªùng m·∫∑c ƒë·ªãnh v√†o data n·∫øu thi·∫øu.
    """
    result = defaults.copy()
    for key, default_value in defaults.items():
        if key in data:
            if isinstance(default_value, dict) and isinstance(data[key], dict):
                result[key] = fill_defaults(data[key], default_value)
            else:
                result[key] = data[key]
    return result


def extract_first_json_object(json_str: str):
    s = json_str.strip()
    if not s or s is None or s == "":
        print("‚ùå Chu·ªói r·ªóng.")
        return DEFAULT_OBJECT
    # T√¨m d·∫•u '{' ƒë·∫ßu ti√™n
    start_index = s.find('{')
    if start_index == -1:
        print("‚ùå Kh√¥ng t√¨m th·∫•y JSON object n√†o.")
        return DEFAULT_OBJECT

    # Duy·ªát t·ª´ ƒë√≥ ƒë·ªÉ t√¨m d·∫•u '}' k·∫øt th√∫c object ƒë·∫ßu ti√™n
    brace_count = 0
    end_index = -1
    for i in range(start_index, len(s)):
        if s[i] == '{':
            brace_count += 1
        elif s[i] == '}':
            brace_count -= 1
            if brace_count == 0:
                end_index = i + 1  # C·∫Øt ƒë·∫øn sau d·∫•u '}'
                break
    if end_index == -1:
        print("‚ùå Kh√¥ng t√¨m th·∫•y JSON ƒë√≥ng ƒë√∫ng.")
        return DEFAULT_OBJECT

    first_json_str = s[start_index:end_index]
    # Ki·ªÉm tra xem c√≥ parse ƒë∆∞·ª£c kh√¥ng
    try:
        result = json.loads(first_json_str)
        # B·ªï sung field m·∫∑c ƒë·ªãnh n·∫øu thi·∫øu
        return fill_defaults(result, DEFAULT_OBJECT)
    except json.JSONDecodeError:
        return DEFAULT_OBJECT
    

async def track_reference_async(context_queries: Dict, kha_nang_dap_ung_tham_chieu_step: Dict, 
                               max_concurrent: int = 5) -> Dict:
    """
    Phi√™n b·∫£n async c·ªßa track_reference v·ªõi gi·ªõi h·∫°n s·ªë requests ƒë·ªìng th·ªùi
    """
    assistant_id = "asst_FZIBIfjPM3kCoxURARvM27UV"
    
    # T·∫°o semaphore ƒë·ªÉ gi·ªõi h·∫°n s·ªë requests ƒë·ªìng th·ªùi
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def process_single_item(key: str):
        async with semaphore:  # Gi·ªõi h·∫°n s·ªë requests ƒë·ªìng th·ªùi
            try:
                value = context_queries[key]["value"]
                content = kha_nang_dap_ung_tham_chieu_step[key]["relevant_context"]
                module_component = context_queries[key]["ten_hang_hoa"]

                user_prompt = f"""
                C√°c t√†i li·ªáu k·ªπ thu·∫≠t ƒë∆∞·ª£c cung c·∫•p: {content},\n
                ====================================
                module/component: {module_component} ,\n
                ====================================
                yeu_cau_ky_thuat: {value}
                """
                
                print(f"üöÄ ƒêang x·ª≠ l√Ω key: {key}")
                result = await evaluate_technical_requirement_async(user_prompt, assistant_id)
                
                if isinstance(result, str):
                    result = extract_first_json_object(result)
                
                return key, result
                
            except Exception as e:
                print(f"‚ùå L·ªói x·ª≠ l√Ω key {key}: {str(e)}")
                return key, DEFAULT_OBJECT
    
    # T·∫°o tasks cho t·∫•t c·∫£ items
    tasks = [process_single_item(key) for key in kha_nang_dap_ung_tham_chieu_step]
    
    # Ch·∫°y t·∫•t c·∫£ tasks song song
    print(f"üèÉ‚Äç‚ôÇÔ∏è B·∫Øt ƒë·∫ßu x·ª≠ l√Ω {len(tasks)} items v·ªõi {max_concurrent} requests ƒë·ªìng th·ªùi...")
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # X·ª≠ l√Ω k·∫øt qu·∫£
    for result in results:
        if isinstance(result, Exception):
            print(f"‚ùå Task failed: {result}")
            continue
            
        key, processed_result = result

        kha_nang_dap_ung_tham_chieu_step[key]["kha_nang_dap_ung"] = processed_result.get("kha_nang_dap_ung", "")
        kha_nang_dap_ung_tham_chieu_step[key]["tai_lieu_tham_chieu"] = {
            "file": processed_result.get("tai_lieu_tham_chieu", {}).get("file", ""),
            "section": processed_result.get("tai_lieu_tham_chieu", {}).get("section", ""),
            "table_or_figure": processed_result.get("tai_lieu_tham_chieu", {}).get("table_or_figure", ""),
            "page": processed_result.get("tai_lieu_tham_chieu", {}).get("page", 0),
            "evidence": processed_result.get("tai_lieu_tham_chieu", {}).get("evidence", "")
        }
        kha_nang_dap_ung_tham_chieu_step[key].pop("relevant_context", None)
        print(f"‚úÖ Ho√†n th√†nh key: {key}")
    
    print("üéâ Ho√†n th√†nh t·∫•t c·∫£!")
    return kha_nang_dap_ung_tham_chieu_step


# H√†m t·∫°o thread
def create_thread():
    thread = clientOpenAI.beta.threads.create()
    return thread.id

# === EVALUATE TECHNICAL REQUIREMENT ===
async def evaluate_technical_requirement_async(user_prompt: str, assistant_id: str) -> Dict[str, Any]:
    """
    Phi√™n b·∫£n async c·ªßa evaluate_technical_requirement
    """
    def _sync_evaluate():
        # 1. T·∫°o thread ri√™ng cho m·ªói l·∫ßn g·ªçi
        thread = clientOpenAI.beta.threads.create()
        thread_id = thread.id

        # 2. G·ª≠i message v√†o thread
        clientOpenAI.beta.threads.messages.create(
            thread_id=thread_id,
            role="user",
            content=user_prompt
        )

        # 3. T·∫°o run
        run = clientOpenAI.beta.threads.runs.create(
            thread_id=thread_id,
            assistant_id=assistant_id,
            tool_choice={"type": "function", "function": {"name": "Technical_adaptability"}}
        )

        # 4. Ch·ªù assistant x·ª≠ l√Ω (t·ªëi ƒëa 20s)
        for _ in range(20):
            run = clientOpenAI.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)
            if run.status not in ["queued", "in_progress"]:
                break
            time.sleep(1)

        # 5. L·∫•y arguments tr·ª±c ti·∫øp
        if run.status == "requires_action":
            tool_calls = run.required_action.submit_tool_outputs.tool_calls
            best_call = None

            for call in tool_calls:
                try:
                    args = extract_first_json_object(call.function.arguments)
                except json.JSONDecodeError:
                    continue

                if args.get("kha_nang_dap_ung"):  # N·∫øu kh√¥ng r·ªóng
                    best_call = args
                    break  # ∆Øu ti√™n l·∫•y c√°i ƒë·∫ßu ti√™n c√≥ d·ªØ li·ªáu

            # N·∫øu kh√¥ng c√≥ c√°i n√†o kha_nang_dap_ung kh√°c r·ªóng -> l·∫•y c√°i cu·ªëi c√πng
            if not best_call and tool_calls:
                try:
                    best_call = json.loads(tool_calls[-1].function.arguments)
                except json.JSONDecodeError:
                    best_call = DEFAULT_OBJECT
            print(f"‚úÖ Found response: {best_call}")
            return fill_defaults(best_call, DEFAULT_OBJECT)

        elif run.status == "completed":
            messages = clientOpenAI.beta.threads.messages.list(thread_id=thread_id)
            for msg in messages.data:
                print(f"[{msg.role}] {msg.content[0].text.value}")
            return None

        else:
            print(f"Run status: {run.status}")
            return DEFAULT_OBJECT
    
    # Ch·∫°y function sync trong thread pool
    return await asyncio.to_thread(_sync_evaluate)
