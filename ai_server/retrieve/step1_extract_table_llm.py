import json
import os
from llama_index.core import SimpleDirectoryReader
from openai import OpenAI
from dotenv import load_dotenv
import re
import camelot
load_dotenv()

# ƒê·∫∑t API key (n·∫øu ch∆∞a ƒë·∫∑t)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
def extract_json_llm(pdf_path):
    table_to_markdown= extract_table_markdown(pdf_path)
    prompt = prompt_llm(table_to_markdown)
    response = client.responses.create(
        model="gpt-4o-mini",  # Ho·∫∑c gpt-4o-mini
        input=prompt,
        temperature=0
    )

    output_text = response.output_text.strip()
    # Lo·∫°i b·ªè c√°c kh·ªëi ```json ho·∫∑c ```
    data = re.sub(r"^```json\s*|\s*```$", "", output_text, flags=re.MULTILINE).strip()
    return data

def prompt_llm(markdown_content):
    prompt = f"""
    B·∫°n l√† tr·ª£ l√Ω tr√≠ch xu·∫•t c·∫•u tr√∫c. H√£y ph√¢n t√≠ch Markdown sau v√† t·∫°o JSON theo QUY T·∫ÆC, ch·ªâ s·ª≠ d·ª•ng c√°c b·∫£ng li√™n quan th√¥ng s·ªë k·ªπ thu·∫≠t v√† c√°c ti√™u chu·∫©n t·ªëi thi·ªÉu ‚Äî th∆∞·ªùng l√† b·∫£ng g·ªìm 3 c·ªôt: "STT", "H√†ng h√≥a", "Y√™u c·∫ßu k·ªπ thu·∫≠t".

    M·ª§C TI√äU JSON:
    [
    {{
        "ten_san_pham": "<string>",
        "cac_muc": [
        {{
            "ten_hang_hoa": "<string>",
            "thong_so_ky_thuat": {{
            "<ID1>": "<string ho·∫∑c list [<t√™n>, <m√¥ t·∫£>]>",
            "<ID2>": "<...>"
            }}
        }},
        ...
        ]
    }},
    ...
    ]

    QUY T·∫ÆC:
    1. M·ªói ph·∫ßn l·ªõn b·∫Øt ƒë·∫ßu b·∫±ng ti√™u ƒë·ªÅ t√™n s·∫£n ph·∫©m s·∫Ω t·∫°o ra m·ªôt ph·∫ßn t·ª≠ trong danh s√°ch JSON (m·ªôt s·∫£n ph·∫©m).
    2. Tr∆∞·ªùng 'ten_san_pham' l·∫•y t·ª´ d√≤ng ti√™u ƒë·ªÅ ƒë·∫ßu ti√™n th·ªÉ hi·ªán t√™n h√†ng h√≥a ch√≠nh.
    3. M·ªói b·∫£ng k·ªπ thu·∫≠t b√™n d∆∞·ªõi ti√™u ƒë·ªÅ l√† m·ªôt nh√≥m 'cac_muc' c·ªßa s·∫£n ph·∫©m ƒë√≥.
    4. Trong m·ªói b·∫£ng:
    - 'ten_hang_hoa' l·∫•y t·ª´ c·ªôt "H√†ng h√≥a" t·∫°i c√°c d√≤ng c√≥ gi√° tr·ªã ·ªü c·ªôt "STT".
    - V·ªõi m·ª•c 'Y√™u c·∫ßu chung':
        - N·∫øu c·ªôt ‚ÄúY√™u c·∫ßu k·ªπ thu·∫≠t‚Äù ch·ª©a nhi·ªÅu m·ª•c g·∫°ch ƒë·∫ßu d√≤ng b·∫Øt ƒë·∫ßu b·∫±ng d·∫•u `-`:
        üëâ **M·ªói m·ª•c b·∫Øt ƒë·∫ßu b·∫±ng `-` l√† m·ªôt th√¥ng s·ªë ri√™ng bi·ªát (atomic), l∆∞u d∆∞·ªõi m·ªôt key ri√™ng.**
        üëâ M·ªói m·ª•c `- ...` s·∫Ω ƒë∆∞·ª£c l∆∞u d·∫°ng `"KEY": "<n·ªôi dung kh√¥ng c√≥ d·∫•u -" >`.
    - V·ªõi m·ª•c 'Th√¥ng s·ªë k·ªπ thu·∫≠t':
        - N·∫øu d√≤ng con c√≥ c·∫£ "H√†ng h√≥a" v√† "Y√™u c·∫ßu k·ªπ thu·∫≠t" ‚Üí l∆∞u d∆∞·ªõi d·∫°ng `"KEY": ["<H√†ng h√≥a>", "<Y√™u c·∫ßu k·ªπ thu·∫≠t>"]`.
    5. M√£ h√≥a key: vi·∫øt t·∫Øt 3 ch·ªØ c√°i ƒë·∫ßu (kh√¥ng d·∫•u, in hoa) c·ªßa 'ten_hang_hoa' + s·ªë th·ª© t·ª± 3 ch·ªØ s·ªë (b·∫Øt ƒë·∫ßu t·ª´ 001).
    6. Chu·∫©n h√≥a n·ªôi dung:
    - B·ªè d·∫•u `-` ƒë·∫ßu d√≤ng n·∫øu c√≥.
    - Kh√¥ng g·ªôp nhi·ªÅu d√≤ng v√†o 1 key. M·ªói d√≤ng k·ªπ thu·∫≠t l√† m·ªôt key ri√™ng bi·ªát, theo th·ª© t·ª±.
    7. Kh√¥ng suy di·ªÖn, kh√¥ng th√™m d·ªØ li·ªáu ngo√†i.
    8. Tr·∫£ v·ªÅ JSON h·ª£p l·ªá (UTF-8), KH√îNG ch√∫ th√≠ch hay gi·∫£i th√≠ch g√¨ th√™m.

    D·ªÆ LI·ªÜU G·ªêC:
    ---
    {markdown_content}
    ---

    H√ÉY TR·∫¢ L·ªúI CH·ªà B·∫∞NG JSON H·ª¢P L·ªÜ.
    """
    return prompt

def table_to_markdown(table_data):
    """Convert table data to markdown format"""
    if not table_data:
        return ""
    
    markdown_lines = []
    
    # Add header row
    if len(table_data) > 0:
        header = "| " + " | ".join(str(cell).strip() for cell in table_data[0]) + " |"
        markdown_lines.append(header)
        
        # Add separator row
        separator = "| " + " | ".join("---" for _ in table_data[0]) + " |"
        markdown_lines.append(separator)
        
        # Add data rows (skip header)
        for row in table_data[1:]:
            row_str = "| " + " | ".join(str(cell).strip() for cell in row) + " |"
            markdown_lines.append(row_str)
    
    return "\n".join(markdown_lines) 

def get_continued_tables(tables, threshold):

    continued_tables = {}
    previous_table = False
    group_counter = 0

    # typical height of a pdf is 842 points and bottom margins are anywhere between 56 and 85 points
    # therefore, accounting for margins, 792
    page_height = 792

    # iterate over the tables
    for i, table in enumerate(tables):

        # if a previous table exists (remember, we start with this as false)
        # and the previous table was on the previous page
        # and the number of columns of both tables is the same
        if previous_table and table.page == previous_table.page + 1 and len(table.cols) == len(previous_table.cols):

            # get the bottom coordinate of the previous table
            # note that for pdfs the origin (0, 0) typically starts from the bottom-left corner of the page,
            # with the y-coordinate increasing as you move upwards
            # this is why for {x0, y0, x1, y1} we need the y0 as the bottom
            previous_table_bottom = previous_table._bbox[1]

            # get the top coordinate of the current table
            # for {x0, y0, x1, y1} we need the y1 as the top
            current_table_top = table._bbox[3]

            # if the previous table ends in the last 15% of the page and the current table starts in the first 15% of the page
            if previous_table_bottom < (threshold / 100) * page_height and current_table_top > (1 - threshold / 100) * page_height:

                # if we don't have started this group of tables
                if (continued_tables.get(group_counter) is None):

                    # start by adding the first table
                    continued_tables[group_counter] = [previous_table]

                # add any of the sunsequent tables to the group
                continued_tables[group_counter].append(table)

            # if this is not a continuation of the previous table
            else:

                # increment the group number
                group_counter += 1

        # if this is not a continuation of the previous table
        else:

            # increment the group number
            group_counter += 1

        # the current table becomes the previous table for the next iteration
        previous_table = table

    # transform the dictionary into an array of arrays
    continued_tables = [value for value in continued_tables.values()]

    # return the combined tables
    return continued_tables

def extract_table_markdown(pdf_path):

    # extract tables
    tables = camelot.read_pdf(pdf_path, flavor = 'lattice', pages = 'all')

    # get continued tables
    continued_tables = get_continued_tables(tables, 15);

    # get the name of the PDF file we are processing (without the extension)
    pdf_file_name = os.path.splitext(os.path.basename(args.path))[0]

    # the path where we're writing the file to
    # (same place where we processed the file from)
    file_path = os.path.dirname(args.path)

    written = []
    longest_table_info = None
    max_content_length = 0

    # iterate over found tables
    for i, table in enumerate(tables):

        # if table was already written as part of a group
        if table in written: continue

        # check if the current table is a continued table
        is_continued = any(table in sublist for sublist in continued_tables)

        # define the filename for the Markdown file
        file_name = f"{pdf_file_name}-page-{table.parsing_report['page']}-table-{table.parsing_report['order']}.md"

        # collect all table data (current table + continued tables if any)
        all_table_data = list(table.data)

        # if the current table is a continued table, append all subsequent continued tables data
        if is_continued:

            # get the index of the group in "continued_tables" associated with the current table
            group_index = next(index for index, sublist in enumerate(continued_tables) if table in sublist)

            # iterate over the tables in said group and append their data
            for continued_table in continued_tables[group_index]:

                # skip the current table as it's already added
                if continued_table == table or continued_table in written: continue

                # append the data of the continued table
                all_table_data.extend(continued_table.data)

                # keep track of written tables so that are not written again in the main iteration
                written.append(continued_table)

        # convert to markdown
        markdown_content = table_to_markdown(all_table_data)
        
        # calculate content length (number of characters)
        content_length = len(markdown_content)
        
        # check if this table has the longest content so far
        if content_length > max_content_length:
            max_content_length = content_length
            longest_table_info = {
                'file_name': file_name,
                'markdown_content': markdown_content,
                'table': table,
                'page': table.parsing_report['page'],
                'order': table.parsing_report['order'],
                'content_length': content_length
            }

    # write only the longest table to file
    return longest_table_info["markdown_content"]