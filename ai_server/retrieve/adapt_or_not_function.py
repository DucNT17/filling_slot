from openai import OpenAI
from dotenv import load_dotenv
import re
import json
import time
clientOpenAI = OpenAI()
from typing import Dict, Tuple
import asyncio
# === ASYNC VERSION OF ADAPT_OR_NOT ===
async def adapt_or_not_async(kha_nang_dap_ung_tham_chieu_step: Dict, 
                           adapt_or_not_step: Dict, 
                           all_requirements: Dict,
                           context_queries: Dict,
                           max_concurrent: int = 5) -> Tuple[Dict, Dict]:
    """
    PhiÃªn báº£n async cá»§a hÃ m adapt_or_not
    """
    assistant_id = "asst_SIWbRtRbvCxXS9dgqvtj9U8O"
    print(f"Assistant ID: {assistant_id}")
    
    # Táº¡o semaphore Ä‘á»ƒ giá»›i háº¡n sá»‘ requests Ä‘á»“ng thá»i
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def process_requirement(key: str):
        async with semaphore:
            try:
                print(f"ğŸš€ Äang xá»­ lÃ½ requirement: {key}")
                
                dap_ung_ky_thuat = ""
                tai_lieu_tham_chieu = ""
                
                # Thu tháº­p thÃ´ng tin tá»« táº¥t cáº£ items trong requirement
                for item in all_requirements[key]:
                    if item not in kha_nang_dap_ung_tham_chieu_step:
                        continue
                        
                    yeu_cau_ky_thuat = context_queries[item].get('yeu_cau_ky_thuat_chi_tiet', "")
                    kha_nang_dap_ung = kha_nang_dap_ung_tham_chieu_step[item].get('kha_nang_dap_ung', "")
                    dap_ung_ky_thuat += f"{yeu_cau_ky_thuat} || {kha_nang_dap_ung}\n"
            
                    tai_lieu = kha_nang_dap_ung_tham_chieu_step[item].get('tai_lieu_tham_chieu', {})
                    file = tai_lieu.get("file", "")
                    page = tai_lieu.get("page", "")
                    table_or_figure = tai_lieu.get("table_or_figure", "")
                    evidence = tai_lieu.get("evidence", "")
            
                    tai_lieu_text = f"{file}, trang: {page}"
                    if table_or_figure:
                        tai_lieu_text += f", trong báº£ng(figure): {table_or_figure}"
                    tai_lieu_text += f", evidence: {evidence}\n\n"
                    tai_lieu_tham_chieu += tai_lieu_text
                
                # Chá»‰ xá»­ lÃ½ náº¿u cÃ³ dá»¯ liá»‡u
                if dap_ung_ky_thuat and tai_lieu_tham_chieu:
                    print(f"ğŸ“ Gá»i API cho key: {key}")
                    result = await Evaluator_adaptability_async(dap_ung_ky_thuat, assistant_id)
                    result = parse_output_text(result)  # result Ä‘Ã£ lÃ  dict
                    
                    output_text = result['Ä‘Ã¡p á»©ng ká»¹ thuáº­t']
                    
                    print(f"âœ… HoÃ n thÃ nh key: {key}")
                    return key, output_text, tai_lieu_tham_chieu
                else:
                    print(f"âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u cho key: {key}")
                    return key, None, None
                    
            except Exception as e:
                print(f"âŒ Lá»—i xá»­ lÃ½ key {key}: {str(e)}")
                return key, None, None
    
    # Táº¡o tasks cho táº¥t cáº£ requirements
    tasks = [process_requirement(key) for key in all_requirements]
    
    print(f"ğŸƒâ€â™‚ï¸ Báº¯t Ä‘áº§u xá»­ lÃ½ {len(tasks)} requirements vá»›i {max_concurrent} requests Ä‘á»“ng thá»i...")
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Xá»­ lÃ½ káº¿t quáº£
    for result in results:
        weight = 0
        if isinstance(result, Exception):
            print(f"âŒ Task failed: {result}")
            continue
            
        key, output_text, tai_lieu_tham_chieu = result
        
        if output_text is not None and tai_lieu_tham_chieu is not None:
            if key not in adapt_or_not_step:
                adapt_or_not_step[key] = []
            weight = len(all_requirements[key])  # Trá»ng sá»‘ lÃ  sá»‘ lÆ°á»£ng item Ä‘Ã£ cÃ³
            adapt_or_not_step[key].append(weight)
            adapt_or_not_step[key].append(output_text)
            adapt_or_not_step[key].append(tai_lieu_tham_chieu)
    
    print("ğŸ‰ HoÃ n thÃ nh táº¥t cáº£ requirements!")
    return kha_nang_dap_ung_tham_chieu_step, adapt_or_not_step


def parse_output_text(output_text: str) -> dict:
    DEFAULT_JSON = {"Ä‘Ã¡p á»©ng ká»¹ thuáº­t": "0"}
    if output_text is None or output_text.strip() == "":
        return DEFAULT_JSON.copy()
    # B1: TÃ¬m pháº§n JSON Ä‘áº§u tiÃªn trong chuá»—i
    match = re.search(r"\{.*\}", output_text, re.DOTALL)
    if not match:
        return DEFAULT_JSON.copy()

    json_str = match.group(0).strip()

    # B2: Parse JSON
    try:
        data = json.loads(json_str)
    except json.JSONDecodeError:
        return DEFAULT_JSON.copy()

    # B3: Náº¿u khÃ´ng cÃ³ key thÃ¬ tráº£ máº·c Ä‘á»‹nh
    if "Ä‘Ã¡p á»©ng ká»¹ thuáº­t" not in data:
        return DEFAULT_JSON.copy()

    return data



# HÃ m táº¡o thread
def create_thread():
    thread = clientOpenAI.beta.threads.create()
    return thread.id

# === ASYNC VERSION OF EVALUATOR_ADAPTABILITY ===
async def Evaluator_adaptability_async(user_prompt: str, assistant_id: str = "asst_SIWbRtRbvCxXS9dgqvtj9U8O") -> str:
    """
    PhiÃªn báº£n async cá»§a Evaluator_adaptability
    """
    def _sync_evaluate():
        # 1. Táº¡o thread riÃªng cho má»—i láº§n gá»i
        thread = clientOpenAI.beta.threads.create()
        thread_id = thread.id

        # 2. Gá»­i message vÃ o thread
        clientOpenAI.beta.threads.messages.create(
            thread_id=thread_id,
            role="user",
            content=user_prompt
        )

        # 3. Táº¡o run
        run = clientOpenAI.beta.threads.runs.create(
            thread_id=thread_id,
            assistant_id=assistant_id,
            tool_choice={"type": "function", "function": {"name": "evaluate_requirement_fulfillment"}}
        )

        # 4. Chá» assistant xá»­ lÃ½ (tá»‘i Ä‘a 20s)
        for _ in range(20):
            run = clientOpenAI.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)
            if run.status not in ["queued", "in_progress"]:
                break
            time.sleep(1)

        # 5. Láº¥y arguments trá»±c tiáº¿p
        if run.status == "requires_action":
            call = run.required_action.submit_tool_outputs.tool_calls[0]
            print(f"ğŸ‘‰ Assistant Ä‘Ã£ gá»i tool: {call.function.name}")
            print("ğŸ§  Dá»¯ liá»‡u JSON assistant muá»‘n tráº£ vá»:")
            print(call.function.arguments)
            return call.function.arguments

        elif run.status == "completed":
            messages = clientOpenAI.beta.threads.messages.list(thread_id=thread_id)
            for msg in messages.data:
                print(f"hello:.........[{msg.role}] {msg.content[0].text.value}")
            return None

        else:
            print(f"Run status: {run.status}")
            return None
    
    # Cháº¡y function sync trong thread pool
    return await asyncio.to_thread(_sync_evaluate)