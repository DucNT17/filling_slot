from ai_server.retrieve2.step4_retrieve import retrieve_results
from openai import AsyncOpenAI  # Changed to AsyncOpenAI
import json 
import asyncio
import re
import os
from dotenv import load_dotenv
load_dotenv()

# Use AsyncOpenAI instead of OpenAI
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

DEFAULT_OBJECT = {
    "kha_nang_dap_ung": "",
    "tai_lieu_tham_chieu": {
        "file": "",
        "section": "",
        "table_or_figure": "",
        "page": 0,
        "evidence": ""
    }
}

def fill_defaults(data: dict, defaults: dict) -> dict:
    """
    ƒê·ªá quy b·ªï sung c√°c tr∆∞·ªùng m·∫∑c ƒë·ªãnh v√†o data n·∫øu thi·∫øu.
    """
    result = defaults.copy()
    for key, default_value in defaults.items():
        if key in data:
            if isinstance(default_value, dict) and isinstance(data[key], dict):
                result[key] = fill_defaults(data[key], default_value)
            else:
                result[key] = data[key]
    return result


def extract_first_json_object(json_str: str):
    s = json_str.strip()
    if not s or s is None or s == "":
        print("‚ùå Chu·ªói r·ªóng.")
        return DEFAULT_OBJECT
    # T√¨m d·∫•u '{' ƒë·∫ßu ti√™n
    start_index = s.find('{')
    if start_index == -1:
        print("‚ùå Kh√¥ng t√¨m th·∫•y JSON object n√†o.")
        return DEFAULT_OBJECT

    # Duy·ªát t·ª´ ƒë√≥ ƒë·ªÉ t√¨m d·∫•u '}' k·∫øt th√∫c object ƒë·∫ßu ti√™n
    brace_count = 0
    end_index = -1
    for i in range(start_index, len(s)):
        if s[i] == '{':
            brace_count += 1
        elif s[i] == '}':
            brace_count -= 1
            if brace_count == 0:
                end_index = i + 1  # C·∫Øt ƒë·∫øn sau d·∫•u '}'
                break
    if end_index == -1:
        print("‚ùå Kh√¥ng t√¨m th·∫•y JSON ƒë√≥ng ƒë√∫ng.")
        return DEFAULT_OBJECT

    first_json_str = s[start_index:end_index]
    # Ki·ªÉm tra xem c√≥ parse ƒë∆∞·ª£c kh√¥ng
    try:
        result = json.loads(first_json_str)
        # B·ªï sung field m·∫∑c ƒë·ªãnh n·∫øu thi·∫øu
        return fill_defaults(result, DEFAULT_OBJECT)
    except json.JSONDecodeError:
        return DEFAULT_OBJECT

async def track_reference(pdf_path, filename_ids, collection_name, max_concurrent=10):
    """
    Async version of track_reference with concurrent processing
    Note: Reduced max_concurrent from 10 to 5 for OpenAI rate limits
    """
    # Semaphore ƒë·ªÉ ki·ªÉm so√°t s·ªë l∆∞·ª£ng requests ƒë·ªìng th·ªùi
    semaphore = asyncio.Semaphore(max_concurrent)
    
    assistant_id = "asst_FZIBIfjPM3kCoxURARvM27UV"
    print(f"Assistant ID: {assistant_id}")

    # T·∫°o thread (now async)
    thread_id = await create_thread()
    print(f"Thread ID: {thread_id}")

    # Retrieve results
    context_queries, product_keys = await retrieve_results(pdf_path, filename_ids, collection_name)
    
    # T·∫°o danh s√°ch tasks ƒë·ªÉ x·ª≠ l√Ω ƒë·ªìng th·ªùi
    tasks = []
    for key in context_queries:
        task = process_query_with_semaphore(
            semaphore,
            key,
            context_queries[key],
            assistant_id
        )
        tasks.append(task)
    
    # Ch·∫°y t·∫•t c·∫£ tasks ƒë·ªìng th·ªùi
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # C·∫≠p nh·∫≠t k·∫øt qu·∫£ v√†o context_queries
    for key, result in zip(context_queries.keys(), results):
        if isinstance(result, Exception):
            print(f"‚ùå L·ªói x·ª≠ l√Ω key {key}: {result}")
            continue
            
        # if result is None:
        #     print(f"‚ö†Ô∏è Kh√¥ng c√≥ k·∫øt qu·∫£ cho key {key}")
        #     continue
            
        context_queries[key]["kha_nang_dap_ung"] = result.get('kha_nang_dap_ung', '')
        context_queries[key]["tai_lieu_tham_chieu"] = {
            "file": result.get('tai_lieu_tham_chieu', {}).get('file', ''),
            "section": result.get('tai_lieu_tham_chieu', {}).get('section', ''),
            "table_or_figure": result.get('tai_lieu_tham_chieu', {}).get('table_or_figure', ''),
            "page": result.get('tai_lieu_tham_chieu', {}).get('page', 0),
            "evidence": result.get('tai_lieu_tham_chieu', {}).get('evidence', '')
        }
        context_queries[key].pop("relevant_context", None)  # Xo√° tr∆∞·ªùng kh√¥ng c·∫ßn thi·∫øt
    
    return context_queries, product_keys


async def process_query_with_semaphore(semaphore, key, query_data, assistant_id):
    """
    Process a single query with semaphore control
    """
    async with semaphore:
        value = query_data["value"]
        content = query_data["relevant_context"]
        module_component = query_data["ten_hang_hoa"]

        # T·∫°o user prompt
        user_prompt = f'''
        C√°c t√†i li·ªáu k·ªπ thu·∫≠t ƒë∆∞·ª£c cung c·∫•p: {content},
        module/component: {module_component} ,
        yeu_cau_ky_thuat: {value},
        '''

        # G·ªçi h√†m ƒë√°nh gi√°
        result = await evaluate_technical_requirement(user_prompt, assistant_id)
        if isinstance(result, str):
            result = extract_first_json_object(result)
            
        return result


# Now truly async create_thread
async def create_thread():
    """
    Async version of create_thread
    """
    thread = await client.beta.threads.create()
    return thread.id


# === FULLY ASYNC EVALUATE TECHNICAL REQUIREMENT ===
async def evaluate_technical_requirement(user_prompt, assistant_id):
    """
    Fully async version of evaluate_technical_requirement
    """
    try:
        # 1. T·∫°o thread ri√™ng cho m·ªói l·∫ßn g·ªçi
        thread = await client.beta.threads.create()
        thread_id = thread.id

        # 2. G·ª≠i message v√†o thread
        await client.beta.threads.messages.create(
            thread_id=thread_id,
            role="user",
            content=user_prompt
        )

        # 3. T·∫°o run
        run = await client.beta.threads.runs.create(
            thread_id=thread_id,
            assistant_id=assistant_id,
            tool_choice={"type": "function", "function": {"name": "Technical_adaptability"}}
        )

        # 4. Ch·ªù assistant x·ª≠ l√Ω (t·ªëi ƒëa 30s) v·ªõi async sleep
        for i in range(30):
            run = await client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)
            if run.status not in ["queued", "in_progress"]:
                break
            await asyncio.sleep(1)  # Now using async sleep
        
        # 5. L·∫•y arguments tr·ª±c ti·∫øp
        if run.status == "requires_action":
            call = run.required_action.submit_tool_outputs.tool_calls[0]
            print(f"üëâ Assistant ƒë√£ g·ªçi tool: {call.function.name}")
            print("üß† D·ªØ li·ªáu JSON assistant mu·ªën tr·∫£ v·ªÅ:")
            print(call.function.arguments)
            return call.function.arguments

        elif run.status == "completed":
            messages = await client.beta.threads.messages.list(thread_id=thread_id)
            for msg in messages.data:
                print(f"[{msg.role}] {msg.content[0].text.value}")
            return None

        else:
            print(f"Run status: {run.status}")
            return DEFAULT_OBJECT
            
    except Exception as e:
        print(f"‚ùå Error in evaluate_technical_requirement: {e}")
        return DEFAULT_OBJECT
